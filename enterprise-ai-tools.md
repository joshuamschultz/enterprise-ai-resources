# ğŸš€ Awesome Enterprise AI Tools

> Production-grade tools for building AI systems at enterprise scale

**Last Updated:** 2025-11-10

---

## ğŸ“– Table of Contents

- [Data Validation & Type Safety](#-data-validation--type-safety)
- [NLP & Text Processing](#-nlp--text-processing)
- [Document Ingestion & ETL](#-document-ingestion--etl)
- [Data Curation](#-data-curation)
- [Distributed Computing & Processing](#-distributed-computing--processing)
- [Data Privacy & Security](#-data-privacy--security)
- [Vector Databases](#-vector-databases)
- [Embedding Models](#-embedding-models)
- [Reranking & Retrieval](#-reranking--retrieval)
- [LLM Providers](#-llm-providers)
- [LLM Inference & Serving](#-llm-inference--serving)
- [Model Registry & Versioning](#-model-registry--versioning)
- [Prompt Management & LLMOps](#-prompt-management--llmops)
- [LLM Security & Guardrails](#-llm-security--guardrails)
- [RAG Frameworks](#-rag-frameworks)
- [Agentic Workflows & Orchestration](#-agentic-workflows--orchestration)
- [RAG Evaluation & Testing](#-rag-evaluation--testing)
- [Observability & Monitoring](#-observability--monitoring)
- [Cloud Platforms](#-cloud-platforms)

---

## ğŸ›¡ï¸ Data Validation & Type Safety

### Pydantic
**ğŸ”— Links:** [Website](https://docs.pydantic.dev) Â· [GitHub](https://github.com/pydantic/pydantic) Â· [Pydantic AI](https://ai.pydantic.dev)

**âš¡ What:** Type-safe data validation for Python with AI agent framework

**ğŸ¯ Use When:**
- Need type safety for LLM outputs with JSON schema enforcement
- Building production AI apps requiring data integrity and consistency
- Validating API inputs/outputs across enterprise services
- Creating structured outputs from unstructured LLM responses

**ğŸ’ª Why:**
- 360M+ downloads/month, used by all FAANG companies
- Model-agnostic: OpenAI, Anthropic, Gemini, Cohere, AWS, Azure, GCP
- MIT licensed for commercial/enterprise use
- Reduces runtime errors, streamlines debugging

**ğŸ“Š License:** MIT | **Support:** Community + Enterprise consulting

---

## ğŸ”¤ NLP & Text Processing

### spaCy
**ğŸ”— Links:** [Website](https://spacy.io) Â· [GitHub](https://github.com/explosion/spaCy)

**âš¡ What:** Industrial-strength NLP with production-ready pipelines

**ğŸ¯ Use When:**
- Named entity recognition, POS tagging, dependency parsing at scale
- Preprocessing text for ML/LLM applications
- Building custom NLP pipelines for domain-specific text
- Processing large volumes (millions of documents) efficiently

**ğŸ’ª Why:**
- C-like speed (Cython core), handles massive text volumes
- State-of-the-art neural models, 100+ pre-trained pipelines
- Latest release: Nov 2025, actively maintained
- Built specifically for production use, not research

**ğŸ“Š License:** MIT | **Support:** Community + Commercial custom pipelines

---

## ğŸ“„ Document Ingestion & ETL

### Unstructured.io
**ğŸ”— Links:** [Website](https://unstructured.io) Â· [Docs](https://docs.unstructured.io) Â· [GitHub](https://github.com/Unstructured-IO/unstructured)

**âš¡ What:** ETL platform transforming unstructured docs â†’ AI-ready data

**ğŸ¯ Use When:**
- Processing 25+ file types (PDFs, Word, HTML, emails, PowerPoints, images)
- Building RAG applications requiring diverse document ingestion
- GDPR/HIPAA/SOC 2 compliance needed for document processing
- High-volume automated pipelines with 50+ source/destination connectors

**ğŸ’ª Why:**
- 82% Fortune 1000 adoption, SOC 2 Type 2 / HIPAA / GDPR ready
- Continuous ingestion with flexible chunking and embedding strategies
- Pythonic API + managed platform options

**ğŸ“Š License:** Apache 2.0 | **Support:** Plus + Enterprise tiers

---

### Docling
**ğŸ”— Links:** [Website](https://www.docling.ai) Â· [Docs](https://docling.ai/docs) Â· [GitHub](https://github.com/DS4SD/docling)

**âš¡ What:** MIT-licensed document conversion preserving layout & structure

**ğŸ¯ Use When:**
- High-accuracy parsing for business intelligence
- Preserving complex elements: tables, equations, code blocks
- On-premise deployments with resource constraints
- Open-source alternative to commercial document AI

**ğŸ’ª Why:**
- Powered by DocLayNet (layout) + TableFormer (tables) AI models
- 10k GitHub stars in <1 month, #1 trending Nov 2024
- Runs efficiently on commodity hardware
- Red Hat RHEL AI support, IBM Granite integration

**ğŸ“Š License:** MIT | **Support:** IBM + Red Hat RHEL AI

---

## ğŸ“¦ Data Curation

### NVIDIA NeMo Curator
**ğŸ”— Links:** [Website](https://developer.nvidia.com/nemo-curator) Â· [GitHub](https://github.com/NVIDIA-NeMo/Curator)

**âš¡ What:** GPU-accelerated data curation for trillion-token datasets

**ğŸ¯ Use When:**
- Pre-training data prep for foundation models (LLMs, VLMs, multimodal)
- Large-scale dataset quality improvement and deduplication (100+ PB)
- Synthetic data generation and filtering pipelines
- Processing speed critical (17x faster vs CPU)

**ğŸ’ª Why:**
- Complete pipeline: download â†’ extract â†’ clean â†’ dedupe â†’ blend
- Pythonic APIs using RAPIDS (cuDF, cuGraph, cuML)
- Part of NVIDIA NeMo suite for full AI lifecycle

**ğŸ“Š License:** Apache 2.0 | **Support:** NVIDIA AI Enterprise

---

## ğŸ”§ Distributed Computing & Processing

### NVIDIA RAPIDS
**ğŸ”— Links:** [Website](https://rapids.ai) Â· [Docs](https://docs.rapids.ai) Â· [GitHub](https://github.com/rapidsai)

**âš¡ What:** GPU-accelerated pandas/scikit-learn with zero code changes

**ğŸ¯ Use When:**
- Large-scale data preprocessing and feature engineering
- Real-time analytics requiring sub-second response
- Cost optimization: replace CPU clusters with smaller GPU clusters
- EDA on billion-row datasets, graph analytics at scale

**ğŸ’ª Why:**
- 50x faster end-to-end data science workflows
- Zero code change: cuDF (pandas), cuML (scikit-learn), cuGraph (NetworkX)
- PayPal 70% cost reduction, CapitalOne 100x faster training
- Spark acceleration via RAPIDS Accelerator

**ğŸ“Š License:** Apache 2.0 | **Support:** NVIDIA AI Enterprise

---

### Ray
**ğŸ”— Links:** [Website](https://www.ray.io) Â· [Docs](https://docs.ray.io) Â· [GitHub](https://github.com/ray-project/ray)

**âš¡ What:** Unified framework for scaling AI/ML from laptop â†’ cluster

**ğŸ¯ Use When:**
- Distributed training of foundation models and neural networks
- Multi-model serving with dynamic batching and autoscaling
- Hyperparameter optimization (1000s of trials)
- Any Python workload needing horizontal scaling

**ğŸ’ª Why:**
- Powers OpenAI ChatGPT infrastructure
- Unified APIs: Ray Data, Train, Serve, Tune, RLlib
- Scales with minimal code changes (often 1 line)
- Azure support: fully managed first-party service (Nov 2025)
- All accelerators: NVIDIA, AMD, Intel, Google TPUs, CPUs

**ğŸ“Š License:** Apache 2.0 | **Support:** Anyscale (managed on Azure/AWS)

---

## ğŸ” Data Privacy & Security

### Microsoft Presidio
**ğŸ”— Links:** [Website](https://microsoft.github.io/presidio) Â· [GitHub](https://github.com/microsoft/presidio)

**âš¡ What:** PII detection, redaction, and anonymization for text/images

**ğŸ¯ Use When:**
- Protecting data before LLM API calls (prevent data leakage)
- GDPR/HIPAA/CCPA compliance for data anonymization
- RAG systems requiring PII removal from documents
- Real-time data masking in chatbots and agents

**ğŸ’ª Why:**
- Two-engine architecture: Analyzer (detect) + Anonymizer (redact/mask/encrypt)
- Context-aware detection: NER, regex, checksums, multi-language
- Multiple anonymization strategies: redact, mask, hash, encrypt, synthetic
- LangGraph integration for PII-aware workflows

**âš ï¸ Note:** Automated detection, cannot guarantee 100% PII identification

**ğŸ“Š License:** MIT | **Support:** Community + Microsoft backing

---

## ğŸ’¾ Vector Databases

### Milvus
**ğŸ”— Links:** [Website](https://milvus.io) Â· [Docs](https://milvus.io/docs) Â· [GitHub](https://github.com/milvus-io/milvus)

**âš¡ What:** Open-source vector database built for GenAI at massive scale

**ğŸ¯ Use When:**
- Similarity search on billions of high-dimensional vectors
- RAG applications requiring fast, scalable vector search
- Mission-critical AI apps (NVIDIA, Meta, Salesforce use it)
- Need flexible deployment: Lite (prototyping) â†’ Standalone â†’ Distributed

**ğŸ’ª Why:**
- 5,000+ enterprise users, 35,000 GitHub stars
- 72% less memory, 4x faster queries vs Elasticsearch (Milvus 2.6, June 2025)
- Enterprise security: RBAC, TLS encryption, user authentication
- Unified API across all deployment models

**ğŸ“Š License:** Apache 2.0 | **Support:** Zilliz Cloud (managed service from $99/mo)

---

### PostgreSQL + pgvector
**ğŸ”— Links:** [PostgreSQL](https://www.postgresql.org) Â· [pgvector](https://github.com/pgvector/pgvector)

**âš¡ What:** PostgreSQL extension for high-performance vector similarity search

**ğŸ¯ Use When:**
- <100M vectors (best TCO at this scale)
- Unified relational + vector workloads (no separate DB needed)
- Need PostgreSQL ecosystem: security, backup, replication
- Cloud-managed options: AWS RDS/Aurora, GCP AlloyDB, Azure

**ğŸ’ª Why:**
- 9x faster queries (pgvector 0.8.0 breakthrough)
- Supports 2,000-dim vectors (standard), 4,000-dim (halfvec)
- Binary quantization for compressed storage
- Google AlloyDB adds ScaNN index (12 years Google Research)

**ğŸ“Š License:** PostgreSQL License | **Support:** Major cloud providers

---

### Chroma
**ğŸ”— Links:** [Website](https://www.trychroma.com) Â· [Docs](https://docs.trychroma.com) Â· [GitHub](https://github.com/chroma-core/chroma)

**âš¡ What:** Open-source embedding database built for AI applications

**ğŸ¯ Use When:**
- Building AI-native applications with embeddings-first design
- Need simple, developer-friendly vector database
- Prototyping to production with same API
- Want both in-memory (dev) and persistent (prod) modes

**ğŸ’ª Why:**
- Python-first design with minimal setup (pip install chromadb)
- Built-in embedding generation with multiple providers
- Filtering by metadata, document content, and similarity
- Scales from laptop to distributed cloud deployment
- LangChain, LlamaIndex, and major framework integrations

**ğŸ“Š License:** Apache 2.0 | **Support:** Community + Chroma Cloud (managed)

---

## ğŸ¯ Embedding Models

### Voyage AI
**ğŸ”— Links:** [Website](https://www.voyageai.com) Â· [Docs](https://docs.voyageai.com) Â· [API](https://docs.voyageai.com/docs/embeddings)

**âš¡ What:** State-of-the-art embedding models for RAG and search

**ğŸ¯ Use When:**
- Need cutting-edge embedding performance (9.74% better than OpenAI)
- Processing long documents (32K token context vs OpenAI's 8K)
- Multilingual retrieval (100+ languages)
- Cost-sensitive deployments (voyage-3.5-lite)

**ğŸ’ª Why:**
- **voyage-3-large:** SOTA across 100 datasets, 8 domains
- Optimized specifically for RAG and retrieval tasks
- Domain-specific models: code, finance, law, multilingual
- 32K token context window vs competitors' 8K-512 tokens
- voyage-3.5-lite: Best cost-performance ratio for production

**ğŸ’° Pricing:** Pay-per-use, volume discounts available

**ğŸ“Š License:** Proprietary | **Support:** Enterprise support available

---

### Cohere Embed
**ğŸ”— Links:** [Website](https://cohere.com/embed) Â· [Docs](https://docs.cohere.com/docs/embeddings) Â· [Pricing](https://cohere.com/pricing)

**âš¡ What:** Multilingual embeddings with 128K context for RAG

**ğŸ¯ Use When:**
- Multilingual applications (100+ languages)
- Processing very long documents (128K tokens = 200 pages)
- Need 96% embedding compression for cost savings
- Regulated industries requiring enterprise compliance

**ğŸ’ª Why:**
- **Embed 4:** Multimodal (text + images), 128K context
- Optimized for agentic search and retrieval
- Outperforms OpenAI/Voyage in many languages
- Available: Cohere Platform, AWS SageMaker, Azure AI Foundry
- Strong compliance for finance, healthcare, manufacturing

**ğŸ’° Pricing:** $0.10/1M tokens (Embed v3), volume discounts

**ğŸ“Š License:** Proprietary | **Support:** Enterprise support

---

## ğŸ” Reranking & Retrieval

### Cohere Rerank
**ğŸ”— Links:** [Website](https://cohere.com/rerank) Â· [Docs](https://docs.cohere.com/docs/reranking) Â· [Pricing](https://cohere.com/pricing)

**âš¡ What:** Industry-leading reranking models for RAG precision

**ğŸ¯ Use When:**
- Boosting RAG retrieval accuracy (15%+ improvement typical)
- Multi-stage retrieval pipelines (fast retrieval + precise reranking)
- Need to reduce LLM context window (fewer, better results)
- Multilingual reranking required

**ğŸ’ª Why:**
- Significantly improves relevance vs vector search alone
- Reduces tokens sent to LLM â†’ lower costs
- Cross-encoder architecture for semantic relevance
- Multilingual support (100+ languages)
- Integrates with all major vector databases

**ğŸ’° Pricing:** $1-$2 per 1K searches (volume discounts)

**ğŸ“Š License:** Proprietary | **Support:** Enterprise support

---

## ğŸ¤– LLM Providers

### OpenAI
**ğŸ”— Links:** [Website](https://openai.com) Â· [API Docs](https://platform.openai.com/docs) Â· [Pricing](https://openai.com/api/pricing/)

**âš¡ What:** GPT-5 and production LLM APIs for enterprise

**ğŸ¯ Use When:**
- Need cutting-edge reasoning and coding capabilities
- Building production apps with strict SLAs
- Require enterprise security (GDPR, CCPA, SOC 2 Type 2)
- Multi-model routing for cost/quality optimization

**ğŸ’ª Why:**
- GPT-5: 80% fewer hallucinations, 50% cost reduction vs GPT-4
- 1.6% hallucination rate (healthcare), 74.9% SWE-bench accuracy
- Batch API: 50% discount for 24hr processing
- 500+ person enterprise sales team

**ğŸ’° Pricing:** $5-$25/M tokens (GPT-4.1 Sonnet), $20-$80/M (Opus)

**ğŸ“Š License:** Proprietary | **Support:** Enterprise plans available

---

### Anthropic Claude
**ğŸ”— Links:** [Website](https://www.claude.com) Â· [API](https://www.anthropic.com/api) Â· [Pricing](https://www.claude.com/pricing)

**âš¡ What:** Claude 4 Sonnet/Opus with 1M token context window

**ğŸ¯ Use When:**
- Processing long documents (750k words, 75k lines of code)
- Need constitutional AI for safer, more aligned outputs
- Financial services (AIG: 5x faster underwriting, 75%â†’90% accuracy)
- AWS Bedrock or Google Vertex AI integration

**ğŸ’ª Why:**
- 1M token context (API), 200K (web)
- Claude Code bundled in Team/Enterprise plans (Aug 2025)
- Enterprise: self-serve seat management, usage analytics, spend controls
- Available: AWS Marketplace, Bedrock, Vertex AI

**ğŸ’° Pricing:** $5-$25/M (Sonnet 4.1), $20-$80/M (Opus 4.1) + thinking tokens

**ğŸ“Š License:** Proprietary | **Support:** Enterprise + AWS Marketplace

---

### Cohere
**ğŸ”— Links:** [Website](https://cohere.com) Â· [API](https://cohere.com/embed) Â· [Pricing](https://cohere.com/pricing)

**âš¡ What:** Enterprise AI with Embed 4 multimodal embeddings

**ğŸ¯ Use When:**
- Building RAG/search for regulated industries (finance, healthcare, manufacturing)
- Need multilingual support (100+ languages)
- Processing long documents (128k tokens = 200 pages)
- Cost optimization with 96% embedding compression

**ğŸ’ª Why:**
- Embed 4: multimodal (text+images), 128k context window
- Optimized for agentic search and retrieval
- Available: Cohere Platform, AWS SageMaker, Azure AI Foundry
- Strong enterprise security for regulated sectors

**ğŸ’° Pricing:** $3/M input, $15/M output (Grok 3), embeddings vary

**ğŸ“Š License:** Proprietary | **Support:** Enterprise support available

---

### xAI Grok
**ğŸ”— Links:** [Website](https://x.ai) Â· [API](https://x.ai/api) Â· [Docs](https://docs.x.ai)

**âš¡ What:** Grok 4 with real-time search and native tool use

**ğŸ¯ Use When:**
- Need real-time information from web/X integration
- Enterprise data extraction, programming, text summarization
- Frontier performance with exceptional token efficiency
- Cost-sensitive workloads (Grok 4 Fast)

**ğŸ’ª Why:**
- Grok 4 Fast: Sept 2025 release, frontier-level performance
- Native tool use and real-time search built-in
- "Most intelligent model in the world" (xAI claim)
- Enterprise arrangements available with custom quotas

**ğŸ’° Pricing:** $3/M input, $15/M output (Grok 3) Â· SuperGrok Heavy $300/mo

**ğŸ“Š License:** Proprietary | **Support:** Enterprise custom arrangements

---

### Hugging Face
**ğŸ”— Links:** [Website](https://huggingface.co) Â· [Inference API](https://huggingface.co/inference-api) Â· [Endpoints](https://endpoints.huggingface.co)

**âš¡ What:** 100k+ open models with unified inference infrastructure

**ğŸ¯ Use When:**
- Need access to open-source models (Llama, Mistral, Falcon, etc.)
- Building multi-model apps with consistent API
- Want deployment flexibility: serverless â†’ dedicated endpoints
- Enterprise Hub for centralized billing and governance

**ğŸ’ª Why:**
- Inference Providers: unified API to world-class inference infrastructure
- Auto-scaling: scales up/down with traffic to save costs
- Supports vLLM, TGI, SGLang, TEI, custom containers
- All data transfers SSL encrypted, no third-party access

**ğŸ’° Pricing:** Free tier â†’ PRO â†’ Enterprise Hub (centralized billing)

**ğŸ“Š License:** Varies by model | **Support:** api-enterprise@huggingface.co

---

## âš¡ LLM Inference & Serving

### Unsloth
**ğŸ”— Links:** [Website](https://unsloth.ai) Â· [GitHub](https://github.com/unslothai/unsloth) Â· [Docs](https://docs.unsloth.ai)

**âš¡ What:** 2-5x faster, 70% less memory LLM fine-tuning

**ğŸ¯ Use When:**
- Fine-tuning LLMs on limited GPU resources (even free Colab/Kaggle)
- Need fast iteration cycles for model customization
- Training with long context lengths (4x longer sequences)
- Cost optimization: reduce training time and GPU requirements

**ğŸ’ª Why:**
- 2-5x faster fine-tuning with 70% less memory usage
- Supports 100+ models: Llama, Mistral, Gemma, Qwen, Phi, etc.
- Works with QLoRA, LoRA, full fine-tuning
- All kernels manually written (no PyTorch Autograd)
- Free tier on Colab/Kaggle, scales to multi-GPU

**ğŸ“Š License:** Apache 2.0 | **Support:** Community + Unsloth Pro ($99-$999/mo)

---

### vLLM
**ğŸ”— Links:** [Website](https://docs.vllm.ai) Â· [GitHub](https://github.com/vllm-project/vllm)

**âš¡ What:** High-throughput, memory-efficient LLM inference engine

**ğŸ¯ Use When:**
- Production serving with strict SLAs (latency, throughput)
- Cost optimization: maximize GPU utilization
- Multi-tenant serving with isolated workloads
- Distributed inference across clusters (disaggregated prefill/decode)

**ğŸ’ª Why:**
- 3-10x lower latency, 2-5x higher throughput vs standard serving
- PagedAttention algorithm eliminates memory fragmentation
- Production Stack (Jan 2025): prefix-aware routing, KV-cache sharing, autoscaling
- llm-d: Kubernetes-native (Red Hat, Google, IBM, NVIDIA, CoreWeave)
- Support for 100+ model architectures, all accelerators

**ğŸ“Š License:** Apache 2.0 | **Support:** Red Hat OpenShift AI + llm-d consortium

---

### NVIDIA NIM
**ğŸ”— Links:** [Website](https://www.nvidia.com/en-us/ai-data-science/products/nim-microservices/) Â· [Developer](https://developer.nvidia.com/nim)

**âš¡ What:** Optimized inference microservices for AI models

**ğŸ¯ Use When:**
- Deploying AI models across cloud, data center, workstation
- Need 5-minute deployment with standard APIs
- Kubernetes scaling and enterprise support required
- Building agentic AI with guardrails (NeMo Guardrails)

**ğŸ’ª Why:**
- Zero-configuration deployment, cloud-native microservices
- Deploy anywhere: NVIDIA-accelerated infrastructure (cloud, DC, workstation)
- Enterprise support: continuous validation, feature branches, NVIDIA experts
- Native integration: Azure AI Foundry, Red Hat OpenShift AI

**ğŸ“Š License:** Part of NVIDIA AI Enterprise | **Support:** NVIDIA AI Enterprise

---

## ğŸ“¦ Model Registry & Versioning

### MLflow
**ğŸ”— Links:** [Website](https://mlflow.org) Â· [Docs](https://mlflow.org/docs/latest) Â· [GitHub](https://github.com/mlflow/mlflow)

**âš¡ What:** Open-source platform for ML lifecycle management

**ğŸ¯ Use When:**
- Managing LLM fine-tuning experiments and versions
- Need centralized model registry with staging/production
- Tracking prompts, parameters, weights, dependencies
- Enterprise governance and lineage tracking required

**ğŸ’ª Why:**
- De facto standard for ML lifecycle (70M+ downloads/month)
- Model Registry: versioning, stage transitions, annotations, lineage
- Native LLM support: prompt packaging, parameter tracking, fine-tuned weights
- Integrates with all major platforms: Databricks, AWS SageMaker, Azure ML
- RBAC and governance for enterprise compliance

**ğŸ“Š License:** Apache 2.0 | **Support:** Community + Databricks MLflow (managed)

---

### Weights & Biases (W&B)
**ğŸ”— Links:** [Website](https://wandb.ai) Â· [Docs](https://docs.wandb.ai) Â· [Pricing](https://wandb.ai/site/pricing)

**âš¡ What:** MLOps platform for experiment tracking and model management

**ğŸ¯ Use When:**
- Large-scale model training with comprehensive tracking
- Need real-time collaboration and experiment comparison
- Building LLMOps with prompt versioning and evaluation
- Want production monitoring and observability

**ğŸ’ª Why:**
- Real-time experiment tracking with visualizations
- Prompt versioning, evaluation frameworks, chain monitoring
- Artifact versioning for datasets, models, and prompts
- Team collaboration with shared dashboards and reports
- Production model monitoring and performance tracking

**ğŸ’° Pricing:** Free tier â†’ Teams ($50/user/mo) â†’ Enterprise (custom)

**ğŸ“Š License:** Proprietary | **Support:** Community + Enterprise support

---

### AWS SageMaker Model Registry
**ğŸ”— Links:** [Website](https://aws.amazon.com/sagemaker) Â· [Docs](https://docs.aws.amazon.com/sagemaker/latest/dg/model-registry.html)

**âš¡ What:** Managed ML model catalog for SageMaker

**ğŸ¯ Use When:**
- AWS-native ML infrastructure required
- Need integrated model deployment pipelines
- Compliance and approval workflows needed
- Building on SageMaker training/inference

**ğŸ’ª Why:**
- Centralized model catalog with metadata and lineage
- Approval workflows for model governance
- Direct integration with SageMaker endpoints
- Cross-account model sharing and discovery
- Foundation model fine-tuning support (2025)

**ğŸ“Š License:** Proprietary (AWS) | **Support:** AWS Enterprise Support

---

## ğŸ›ï¸ Prompt Management & LLMOps

### Portkey
**ğŸ”— Links:** [Website](https://portkey.ai) Â· [Docs](https://docs.portkey.ai) Â· [GitHub](https://github.com/Portkey-AI/gateway)

**âš¡ What:** Production AI gateway with prompt management and observability

**ğŸ¯ Use When:**
- Managing 1600+ LLM providers through unified API
- Need centralized prompt versioning and deployment
- Processing 10B+ monthly LLM requests
- Require AI gateway with guardrails and routing

**ğŸ’ª Why:**
- **AI Gateway:** Unified access to 1600+ LLMs with load balancing
- **Prompt Management:** Version control, A/B testing, rollback
- **Observability:** End-to-end tracing, metrics, debugging
- **Guardrails:** 50+ integrated safety checks
- Fortune 500 trusted, 16K+ developers

**ğŸ’° Pricing:** Free tier â†’ Growth â†’ Enterprise

**ğŸ“Š License:** Apache 2.0 (gateway) | **Support:** Enterprise support

---

### Langfuse
**ğŸ”— Links:** [Website](https://langfuse.com) Â· [Docs](https://langfuse.com/docs) Â· [GitHub](https://github.com/langfuse/langfuse)

**âš¡ What:** Open-source LLM observability and prompt management

**ğŸ¯ Use When:**
- Need open-source observability platform
- Tracking prompt chains and agent workflows
- Real-time monitoring and evaluation
- Self-hosted deployment required

**ğŸ’ª Why:**
- Complete LLM application observability
- Prompt versioning with performance tracking
- User analytics and cost tracking
- LangChain, LlamaIndex, Vercel AI SDK integrations
- Self-hosted or cloud deployment options

**ğŸ’° Pricing:** Open-source (self-hosted) â†’ Cloud (usage-based) â†’ Enterprise

**ğŸ“Š License:** MIT | **Support:** Community + Enterprise

---

## ğŸ”— Agentic Workflows & Orchestration

### LangChain Ecosystem
**ğŸ”— Links:** [LangChain](https://www.langchain.com) Â· [LangGraph](https://www.langchain.com/langgraph) Â· [LangSmith](https://www.langchain.com/langsmith)

**âš¡ What:** Production framework for LLM apps and agents

**ğŸ¯ Use When:**
- Building RAG applications with complex retrieval logic
- Multi-agent systems requiring orchestration and state sharing
- Need provider flexibility (swap OpenAI â†” Anthropic â†” open-source)
- Enterprise observability, evaluation, CI/CD required
- Long-running stateful agents (hours/days/weeks)

**ğŸ’ª Why:**

**LangChain:** 70M+ downloads/mo, 700+ integrations (LLMs, vectors, APIs, tools)

**LangGraph:** 400+ companies deployed agents to prod (2025 beta), stateful multi-agent workflows, human-in-the-loop

**LangSmith:** End-to-end tracing, debugging, monitoring; AWS Marketplace (2025); Cloud, Hybrid, Self-Hosted deployment

**ğŸ“Š License:** MIT | **Support:** LangSmith Plus + Enterprise

---

### Vercel AI SDK
**ğŸ”— Links:** [Website](https://ai-sdk.dev) Â· [Docs](https://ai-sdk.dev/docs) Â· [GitHub](https://github.com/vercel/ai)

**âš¡ What:** TypeScript toolkit for AI-powered frontends

**ğŸ¯ Use When:**
- Building AI chat interfaces with streaming responses
- Next.js applications requiring server-side AI integration
- Need multi-model support (30+ LLM providers)
- Edge runtime deployments for low-latency global inference

**ğŸ’ª Why:**
- Unified API across OpenAI, Anthropic, Google, AWS Bedrock, open-source
- First-class streaming with React Server Components (RSC)
- **AI SDK 6 (beta 2025):** Agent abstraction, tool execution approval, human-in-the-loop
- Vercel AI Cloud: AI Gateway, DDoS/bot protection, WAF, Fluid Compute

**ğŸ’° Pricing:** Free tier â†’ Pro â†’ Enterprise with custom DDoS/IP blocking

**ğŸ“Š License:** Apache 2.0 | **Support:** Vercel Enterprise

---

## ğŸ›¡ï¸ LLM Security & Guardrails

### NVIDIA NeMo Guardrails
**ğŸ”— Links:** [Website](https://www.nvidia.com/en-us/ai-data-science/products/nemo/) Â· [Docs](https://docs.nvidia.com/nemo/guardrails) Â· [GitHub](https://github.com/NVIDIA/NeMo-Guardrails)

**âš¡ What:** Programmable guardrails for conversational AI safety

**ğŸ¯ Use When:**
- Building production LLM applications requiring safety controls
- Need topical guardrails (prevent off-topic responses)
- Preventing hallucinations and unsafe outputs
- Implementing fact-checking and content moderation

**ğŸ’ª Why:**
- Open-source framework from NVIDIA
- Define guardrails as policies in simple configuration files
- Input/output rails for request and response filtering
- Integrates with LangChain, LlamaIndex, custom applications
- Part of NVIDIA NeMo ecosystem for enterprise AI

**ğŸ“Š License:** Apache 2.0 | **Support:** NVIDIA AI Enterprise

---

### Fiddler Guardrails
**ğŸ”— Links:** [Website](https://www.fiddler.ai) Â· [Docs](https://docs.fiddler.ai/docs/guardrails) Â· [Product](https://www.fiddler.ai/blog/introducing-fiddler-guardrails)

**âš¡ What:** Enterprise guardrails for LLM safety and security

**ğŸ¯ Use When:**
- Enterprise-scale protection (5M+ requests/day)
- Need <100ms latency for production apps
- Preventing hallucinations, jailbreaks, prompt injection
- Compliance with safety and security policies

**ğŸ’ª Why:**
- Moderates prompts and responses in real-time
- Pre-built detectors: hallucinations, PII, toxicity, bias
- Custom policy creation for business rules
- Enterprise scalability out of the box
- Integration with major LLM providers

**ğŸ’° Pricing:** Contact for enterprise pricing

**ğŸ“Š License:** Proprietary | **Support:** Enterprise support

---

## ğŸ”§ RAG Frameworks

### LlamaIndex
**ğŸ”— Links:** [Website](https://www.llamaindex.ai) Â· [Docs](https://docs.llamaindex.ai) Â· [GitHub](https://github.com/run-llama/llama_index)

**âš¡ What:** Data framework for building LLM applications

**ğŸ¯ Use When:**
- Building RAG applications with complex data sources
- Need advanced retrieval strategies (hybrid, semantic, keyword)
- Want modular, composable components for data ingestion
- Building agents that query structured and unstructured data

**ğŸ’ª Why:**
- 200+ data connectors (APIs, databases, files, web)
- Advanced indexing: vector, tree, graph, knowledge graph
- Query engines with reasoning capabilities
- Agent tools for multi-step reasoning over data
- Production-ready with observability integrations

**ğŸ“Š License:** MIT | **Support:** Community + LlamaCloud (managed)

---

### Haystack
**ğŸ”— Links:** [Website](https://haystack.deepset.ai) Â· [Docs](https://docs.haystack.deepset.ai) Â· [GitHub](https://github.com/deepset-ai/haystack)

**âš¡ What:** Open-source NLP framework for production RAG

**ğŸ¯ Use When:**
- Building production RAG pipelines at scale
- Need flexible pipeline composition
- Want both retrieval and generation in one framework
- Enterprise search and question answering required

**ğŸ’ª Why:**
- Production-ready RAG pipelines with 30+ integrations
- Modular components: retrievers, readers, rankers, generators
- Support for multiple vector stores and LLM providers
- Built-in evaluation and monitoring
- deepset Cloud for managed deployment

**ğŸ“Š License:** Apache 2.0 | **Support:** Community + deepset Cloud (managed)

---

## ğŸ§ª RAG Evaluation & Testing

### Ragas
**ğŸ”— Links:** [Website](https://www.ragas.io) Â· [Docs](https://docs.ragas.io) Â· [GitHub](https://github.com/explodinggradients/ragas)

**âš¡ What:** Reference-free RAG evaluation with LLM-as-judge

**ğŸ¯ Use When:**
- Evaluating RAG accuracy before production deployment
- Continuous monitoring of production RAG (A/B tests, dashboards)
- Identifying weak points in retrieval or generation stages
- Optimizing retrieval strategies (chunk size, embeddings, reranking)
- Compliance: ensuring factual accuracy and relevance

**ğŸ’ª Why:**
- **4 Core Metrics:** Faithfulness, Answer Relevancy, Context Precision, Context Recall
- No ground truth annotations needed (reference-free)
- Integrates with LangChain, LlamaIndex, observability platforms
- Production feedback loop for continuous improvement
- 2025 trends: GraphRAG, multi-agent evaluation, metric standardization

**ğŸ“Š License:** Apache 2.0 | **Support:** Enterprise support via consultation

---

### DeepEval
**ğŸ”— Links:** [Website](https://www.confident-ai.com) Â· [Docs](https://deepeval.com/docs/getting-started) Â· [GitHub](https://github.com/confident-ai/deepeval) Â· [DeepTeam](https://github.com/confident-ai/deepteam)

**âš¡ What:** Open-source LLM evaluation framework with AI red teaming capabilities

**ğŸ¯ Use When:**
- Security testing LLM applications for vulnerabilities (bias, PII leakage, harmful content)
- Evaluating LLMs with 30+ plug-and-use metrics (faithfulness, hallucination, toxicity)
- Automated adversarial attack simulation (jailbreaking, prompt injection, data extraction)
- CI/CD integration for regression testing and quality gates
- OWASP Top 10 for LLMs and NIST AI Risk Management compliance

**ğŸ’ª Why:**
- **Red Teaming (DeepTeam):** Detect 40+ vulnerability types, simulate 10+ attack methods, no dataset required
- **Evaluation Metrics:** 30+ research-backed metrics for end-to-end and component-level testing
- **Confident AI Platform:** Cloud platform for monitoring, tracing, A/B testing, real-time insights
- Synthetic dataset generation with state-of-the-art evolution techniques
- Integrates with CI/CD, LangChain, AWS Bedrock, Azure AI Foundry
- Data residency options: US (North Carolina) or EU (Frankfurt)
- SOC 2 Type 2 compliant with custom permissions and PII masking

**âš ï¸ Note:** DeepTeam (red teaming) dynamically simulates attacks at runtime; DeepEval (evaluation) requires prepared datasets

**ğŸ“Š License:** Apache 2.0 | **Support:** Confident AI Enterprise + Community

---

## ğŸ“Š Observability & Monitoring

### Prometheus
**ğŸ”— Links:** [Website](https://prometheus.io) Â· [Docs](https://prometheus.io/docs) Â· [GitHub](https://github.com/prometheus/prometheus)

**âš¡ What:** De facto standard for Kubernetes monitoring (90% CNCF adoption)

**ğŸ¯ Use When:**
- Monitoring Kubernetes clusters and applications at scale
- Need multi-dimensional time-series metrics with labels
- Service discovery for ephemeral workloads
- Multi-cluster management (Thanos/Mimir/Cortex for 3-300 clusters)

**ğŸ’ª Why:**
- Multi-dimensional data model matching Kubernetes labels
- Auto-discovery of scrape targets (perfect for K8s)
- Prometheus Operator: declarative full ecosystem management
- Federation, remote storage, GitOps for enterprise scale

**ğŸ“Š License:** Apache 2.0 | **Support:** Community + CNCF

---

### Grafana
**ğŸ”— Links:** [Website](https://grafana.com) Â· [Docs](https://grafana.com/docs) Â· [GitHub](https://github.com/grafana/grafana)

**âš¡ What:** Observability platform for visualizations and dashboards

**ğŸ¯ Use When:**
- Unified observability across metrics, logs, traces, profiles
- Need dynamic dashboards with observability-as-code (Grafana 12)
- Multi-data source visualization (Prometheus, Loki, Splunk, Datadog, etc.)
- AI-powered incident resolution (Grafana Assistant)

**ğŸ’ª Why:**
- **Grafana 12 (May 2025):** Git Sync, dynamic dashboards, native alert management
- Observability as code: version, validate, deploy dashboards like code
- Enterprise plugins: Splunk, ServiceNow, Datadog integrations
- Usage insights: user behavior, dashboard utilization, data source metrics

**ğŸ“Š License:** AGPL 3.0 (OSS) | **Support:** Grafana Enterprise + Cloud

---

### Grafana Loki
**ğŸ”— Links:** [Website](https://grafana.com/oss/loki) Â· [Docs](https://grafana.com/docs/loki) Â· [GitHub](https://github.com/grafana/loki)

**âš¡ What:** Cost-effective log aggregation inspired by Prometheus

**ğŸ¯ Use When:**
- Need cost-effective log aggregation at massive scale
- Familiar with Prometheus (uses same labels/service discovery)
- Kubernetes logs with OpenTelemetry/Grafana Alloy
- Want horizontal scalability with low-cost object storage

**ğŸ’ª Why:**
- Only indexes metadata (labels), not log contents â†’ huge cost savings
- LogQL query language familiar to PromQL users
- 2025: Grafana Alloy ingestion (OTel Collector distribution)
- Deployment modes: Monolithic (simple) â†’ Distributed (scalable)

**ğŸ“Š License:** AGPL 3.0 | **Support:** Grafana Cloud Logs + Enterprise Logs

---

## â˜ï¸ Cloud Platforms

### AWS Bedrock
**ğŸ”— Links:** [Website](https://aws.amazon.com/bedrock) Â· [Docs](https://docs.aws.amazon.com/bedrock)

**âš¡ What:** Managed service for building GenAI applications with foundation models

**ğŸ¯ Use When:**
- Need access to multiple FMs (Anthropic, Meta, Cohere, Mistral, Amazon Titan)
- Building production AI agents at scale with governance
- Require enterprise security, compliance, and private endpoints
- Want unified tool server for multi-agent applications

**ğŸ’ª Why:**
- **AgentCore (Preview 2025):** Runtime, Memory, Gateway for AI agents
- Supports any framework/model, works with LangChain, LlamaIndex, etc.
- Enterprise governance: encryption, access mgmt, model governance
- Success: Robinhood 5B tokens/day, 80% cost reduction, 50% dev time cut

**ğŸ’° Pricing:** Free preview until Sept 16, 2025 â†’ pay-per-use after

**ğŸ“Š License:** Proprietary | **Support:** AWS Enterprise Support

---

### Azure OpenAI Service
**ğŸ”— Links:** [Website](https://azure.microsoft.com/products/ai-services/openai-service) Â· [Docs](https://learn.microsoft.com/azure/ai-services/openai) Â· [Pricing](https://azure.microsoft.com/pricing/details/cognitive-services/openai-service)

**âš¡ What:** Enterprise OpenAI models on Azure with data privacy guarantees

**ğŸ¯ Use When:**
- Need OpenAI models (GPT-5, o1, DALL-E, Whisper) with enterprise SLAs
- Require data residency and compliance (no data leaves Azure)
- Integration with Fabric, Cosmos DB, Azure AI Search
- Microsoft partnership extended through 2032

**ğŸ’ª Why:**
- **New Partnership (Oct 2025):** Microsoft 27% stake, $250B Azure commitment, IP rights through 2032
- GPT-5 GA on Azure AI Foundry (Aug 2025)
- gpt-oss: OpenAI's first open-weight release since GPT-2
- Regional flexibility, private endpoints, compliance built-in

**ğŸ’° Pricing:** Pay-per-use, same as OpenAI API + Azure infra costs

**ğŸ“Š License:** Proprietary | **Support:** Azure Enterprise Support

---

## ğŸ“š Quick Reference

### By Data Flow

```
1. Data Validation â†’ Pydantic
2. Text Processing â†’ spaCy
3. Document Ingestion â†’ Unstructured.io, Docling
4. Data Curation â†’ NeMo Curator
5. Distributed Processing â†’ RAPIDS, Ray
6. Privacy/PII Removal â†’ Presidio
7. Vector Storage â†’ Milvus, PostgreSQL+pgvector, Chroma
8. Embeddings â†’ Voyage AI, Cohere Embed
9. Reranking â†’ Cohere Rerank
10. LLM Providers â†’ OpenAI, Claude, Cohere, Grok, Hugging Face
11. LLM Fine-tuning â†’ Unsloth
12. LLM Inference â†’ vLLM, NIM, Ray
13. Model Registry â†’ MLflow, W&B, SageMaker
14. Prompt Management â†’ Portkey, Langfuse
15. Guardrails â†’ NeMo Guardrails, Fiddler
16. RAG Frameworks â†’ LlamaIndex, Haystack
17. Agent Orchestration â†’ LangChain/LangGraph, Vercel AI SDK
18. RAG Evaluation â†’ Ragas, DeepEval
19. Monitoring â†’ Prometheus, Grafana, Loki
20. Cloud Platforms â†’ AWS Bedrock, Azure OpenAI
```

### By Use Case

**Building RAG Application:**
```
Documents â†’ Unstructured/Docling â†’ Presidio â†’ Chroma/Milvus/pgvector
Embeddings â†’ Voyage AI/Cohere Embed
Retrieval â†’ Vector Search â†’ Cohere Rerank
RAG Framework â†’ LlamaIndex/Haystack
Query â†’ LangChain/Vercel AI SDK â†’ vLLM/NIM/Ray â†’ Response
Guardrails â†’ NeMo Guardrails/Fiddler
Evaluate â†’ Ragas, DeepEval
Red Team â†’ DeepEval/DeepTeam
Monitor â†’ Langfuse, Prometheus, Grafana
Prompt Mgmt â†’ Portkey, Langfuse
```

**Fine-tuning & Serving Foundation Model:**
```
Raw Data â†’ NeMo Curator â†’ RAPIDS (processing) â†’ Ray (distributed training)
Fine-tune â†’ Unsloth
Model Registry â†’ MLflow/W&B/SageMaker
Model â†’ vLLM/NIM/Ray (serving) â†’ Production
Monitor â†’ Prometheus, Grafana
```

**Production LLM App:**
```
Inputs â†’ Pydantic validation â†’ spaCy preprocessing
Distributed Processing â†’ RAPIDS, Ray
Embeddings â†’ Voyage AI/Cohere Embed
Vector Search â†’ Milvus/pgvector/Chroma
Reranking â†’ Cohere Rerank
LLM Gateway â†’ Portkey
LLM â†’ OpenAI/Claude/Cohere via vLLM/NIM/Ray
Guardrails â†’ NeMo Guardrails/Fiddler
Agent Framework â†’ LangChain/Vercel AI SDK/LlamaIndex
Prompt Mgmt â†’ Portkey, Langfuse
Monitor â†’ Langfuse, Prometheus, Grafana, Loki
Cloud â†’ AWS Bedrock or Azure OpenAI
```

---

## ğŸ¢ Enterprise Support Summary

| Tool | License | Enterprise Support |
|------|---------|-------------------|
| Pydantic | MIT | Community + Consulting |
| spaCy | MIT | Community + Commercial pipelines |
| Unstructured.io | Apache 2.0 | Plus + Enterprise |
| Docling | MIT | IBM + Red Hat RHEL AI |
| NeMo Curator | Apache 2.0 | NVIDIA AI Enterprise |
| RAPIDS | Apache 2.0 | NVIDIA AI Enterprise |
| Presidio | MIT | Community + Microsoft |
| Milvus | Apache 2.0 | Zilliz Cloud ($99/mo+) |
| PostgreSQL+pgvector | PostgreSQL | Cloud providers (AWS, GCP, Azure) |
| Chroma | Apache 2.0 | Community + Chroma Cloud |
| Voyage AI | Proprietary | Enterprise support |
| Cohere Embed | Proprietary | Enterprise support |
| Cohere Rerank | Proprietary | Enterprise support |
| OpenAI | Proprietary | Enterprise plans |
| Anthropic Claude | Proprietary | Enterprise + AWS Marketplace |
| Cohere | Proprietary | Enterprise support |
| xAI Grok | Proprietary | Enterprise custom |
| Hugging Face | Varies | Enterprise Hub |
| Unsloth | Apache 2.0 | Unsloth Pro ($99-$999/mo) |
| vLLM | Apache 2.0 | Red Hat OpenShift AI + llm-d |
| NVIDIA NIM | NVIDIA AI Enterprise | NVIDIA AI Enterprise |
| Ray | Apache 2.0 | Anyscale (Azure/AWS managed) |
| MLflow | Apache 2.0 | Databricks MLflow (managed) |
| Weights & Biases | Proprietary | Enterprise support |
| AWS SageMaker | Proprietary (AWS) | AWS Enterprise Support |
| Portkey | Apache 2.0 (gateway) | Enterprise support |
| Langfuse | MIT | Community + Enterprise |
| NeMo Guardrails | Apache 2.0 | NVIDIA AI Enterprise |
| Fiddler Guardrails | Proprietary | Enterprise support |
| LlamaIndex | MIT | Community + LlamaCloud |
| Haystack | Apache 2.0 | Community + deepset Cloud |
| LangChain | MIT | LangSmith Plus + Enterprise |
| Vercel AI SDK | Apache 2.0 | Vercel Enterprise |
| Ragas | Apache 2.0 | Enterprise consultation |
| DeepEval | Apache 2.0 | Confident AI Enterprise + Community |
| Prometheus | Apache 2.0 | CNCF Community |
| Grafana | AGPL 3.0 | Grafana Enterprise + Cloud |
| Loki | AGPL 3.0 | Grafana Enterprise + Cloud |
| AWS Bedrock | Proprietary | AWS Enterprise Support |
| Azure OpenAI | Proprietary | Azure Enterprise Support |

---

## ğŸ”— All Links

**Documentation:**
- [Pydantic](https://docs.pydantic.dev) Â· [spaCy](https://spacy.io) Â· [Unstructured](https://docs.unstructured.io) Â· [Docling](https://docling.ai/docs)
- [NeMo Curator](https://docs.nvidia.com/nemo-framework/user-guide/latest/datacuration/) Â· [RAPIDS](https://docs.rapids.ai) Â· [Presidio](https://microsoft.github.io/presidio)
- [Milvus](https://milvus.io/docs) Â· [pgvector](https://github.com/pgvector/pgvector) Â· [Chroma](https://docs.trychroma.com)
- [Voyage AI](https://docs.voyageai.com) Â· [Cohere Embed](https://docs.cohere.com/docs/embeddings) Â· [Cohere Rerank](https://docs.cohere.com/docs/reranking)
- [OpenAI](https://platform.openai.com/docs) Â· [Claude](https://www.anthropic.com/api) Â· [Cohere](https://cohere.com/embed) Â· [Grok](https://docs.x.ai) Â· [Hugging Face](https://huggingface.co/docs)
- [Unsloth](https://docs.unsloth.ai) Â· [vLLM](https://docs.vllm.ai) Â· [NIM](https://developer.nvidia.com/nim) Â· [Ray](https://docs.ray.io)
- [MLflow](https://mlflow.org/docs/latest) Â· [W&B](https://docs.wandb.ai) Â· [SageMaker](https://docs.aws.amazon.com/sagemaker)
- [Portkey](https://docs.portkey.ai) Â· [Langfuse](https://langfuse.com/docs)
- [NeMo Guardrails](https://docs.nvidia.com/nemo/guardrails) Â· [Fiddler](https://docs.fiddler.ai/docs/guardrails)
- [LlamaIndex](https://docs.llamaindex.ai) Â· [Haystack](https://docs.haystack.deepset.ai)
- [LangChain](https://python.langchain.com) Â· [Vercel AI SDK](https://ai-sdk.dev/docs)
- [Ragas](https://docs.ragas.io) Â· [DeepEval](https://deepeval.com/docs/getting-started)
- [Prometheus](https://prometheus.io/docs) Â· [Grafana](https://grafana.com/docs) Â· [Loki](https://grafana.com/docs/loki)
- [AWS Bedrock](https://docs.aws.amazon.com/bedrock) Â· [Azure OpenAI](https://learn.microsoft.com/azure/ai-services/openai)

**GitHub Repositories:**
- [Pydantic](https://github.com/pydantic/pydantic) Â· [spaCy](https://github.com/explosion/spaCy) Â· [Unstructured](https://github.com/Unstructured-IO/unstructured)
- [Docling](https://github.com/DS4SD/docling) Â· [NeMo](https://github.com/NVIDIA/NeMo) Â· [RAPIDS](https://github.com/rapidsai)
- [Presidio](https://github.com/microsoft/presidio) Â· [Milvus](https://github.com/milvus-io/milvus) Â· [pgvector](https://github.com/pgvector/pgvector) Â· [Chroma](https://github.com/chroma-core/chroma)
- [Unsloth](https://github.com/unslothai/unsloth) Â· [vLLM](https://github.com/vllm-project/vllm) Â· [Ray](https://github.com/ray-project/ray)
- [MLflow](https://github.com/mlflow/mlflow) Â· [Portkey Gateway](https://github.com/Portkey-AI/gateway) Â· [Langfuse](https://github.com/langfuse/langfuse)
- [NeMo Guardrails](https://github.com/NVIDIA/NeMo-Guardrails) Â· [LlamaIndex](https://github.com/run-llama/llama_index) Â· [Haystack](https://github.com/deepset-ai/haystack)
- [LangChain](https://github.com/langchain-ai/langchain) Â· [Vercel AI SDK](https://github.com/vercel/ai)
- [Ragas](https://github.com/explodinggradients/ragas) Â· [DeepEval](https://github.com/confident-ai/deepeval) Â· [DeepTeam](https://github.com/confident-ai/deepteam)
- [Prometheus](https://github.com/prometheus/prometheus) Â· [Grafana](https://github.com/grafana/grafana) Â· [Loki](https://github.com/grafana/loki)

---

## ğŸ¤ Contributing

See `.claude/CLAUDE.md` for guidelines on adding new tools to this list.

**Criteria for inclusion:**
âœ… Production-ready and enterprise-proven
âœ… Active maintenance (2025 updates)
âœ… Clear enterprise value proposition
âœ… Official support channels

---

**Made with â¤ï¸ for the AI Engineering Community**
